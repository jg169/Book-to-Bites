{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "NO47mAC5iGH7",
        "h0agEM-ZkQxb",
        "mrN4PAaN7cEn",
        "Crdhphr34Cdp",
        "-cBD2a7COStG",
        "cW3KEC4PCA5f"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "NO47mAC5iGH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install langchain \n",
        "!pip -q install langchain openai==0.27.0  tiktoken "
      ],
      "metadata": {
        "id": "qZ5JXLe1OlLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install bark (make sure you have torch>=2 for much faster flash-attention)\n",
        "!pip install git+https://github.com/suno-ai/bark.git"
      ],
      "metadata": {
        "id": "YkizeTpG_3T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prompt-optimizer"
      ],
      "metadata": {
        "id": "ZHEmZzoYVecw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tiktoken"
      ],
      "metadata": {
        "id": "gN56MW2GbiqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "h0agEM-ZkQxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ask for API keys and input text\n",
        "\n",
        "ApiKey = input('what is your API key?')\n",
        "\n",
        "text = input('copy and paste a page that you wanted summarized into a soundbite here')"
      ],
      "metadata": {
        "id": "57m38KzgkijL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trimming and counting tokens"
      ],
      "metadata": {
        "id": "mrN4PAaN7cEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#new prompt optimizier for v0.1.0\n",
        "from prompt_optimizer.poptim import EntropyOptim\n"
      ],
      "metadata": {
        "id": "RINWNhb2Va1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#semantically trims prompt with minimal loss of semantic value before trimming \n",
        "prompt = text\n",
        "p_optimizer = EntropyOptim(verbose=True, p=0.1) #reccomended: p = 0.1 represents an 11% reduction in tokens while reducing logiQA accuracy by only 6%; other options such as p = 0.05, 0.25, 0.5 are available(0.5 not reccomended)\n",
        "optimized_prompt = p_optimizer(prompt)\n",
        "optimized_prompt_output = optimized_prompt['content']\n",
        "text = optimized_prompt_output\n",
        "print(text)"
      ],
      "metadata": {
        "id": "bOMDPcnWWeFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt trimming inspired by GPTrim\n",
        "import re\n",
        "from typing import Optional, List\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "o59Wfxx_Ywmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ARTICLES_PREPOSITIONS = {\n",
        "    \"english\": ['the', 'a', 'an', 'in', 'on', 'at', 'for', 'to', 'of']\n",
        "}\n",
        "\n",
        "NEGATION_WORDS = {\n",
        "    \"english\": [\n",
        "        'no',\n",
        "        'nor',\n",
        "        'not',\n",
        "        'don',\n",
        "        \"dont\",\n",
        "        'ain',\n",
        "        'aren',\n",
        "        \"arent\",\n",
        "        'couldn',\n",
        "        \"couldnt\",\n",
        "        'didn',\n",
        "        \"didnt\",\n",
        "        'doesn',\n",
        "        \"doesnt\",\n",
        "        'hadn',\n",
        "        \"hadnt\",\n",
        "        'hasn',\n",
        "        \"hasnt\",\n",
        "        'haven',\n",
        "        \"havent\",\n",
        "        'isn',\n",
        "        \"isnt\",\n",
        "        'mightn',\n",
        "        \"mightnt\",\n",
        "        'mustn',\n",
        "        \"mustnt\",\n",
        "        'needn',\n",
        "        \"neednt\",\n",
        "        'shan',\n",
        "        \"shant\",\n",
        "        'shouldn',\n",
        "        \"shouldnt\",\n",
        "        'wasn',\n",
        "        \"wasnt\",\n",
        "        'weren',\n",
        "        \"werent\",\n",
        "        'won',\n",
        "        \"wont\",\n",
        "        'wouldn',\n",
        "        \"wouldnt\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "PUNCTUATION = [\".\", \",\", \"'\", '\"', \"!\", \"?\", \";\", \":\", \"-\", \"(\", \")\",\"[\",\"]\",\"{\",\"}\"] #now also removes parantheses, brackets, and braces\n",
        "\n",
        "def trim(\n",
        "    text: str, stemmer: Optional[str] = None, language: str = \"english\", remove_spaces: bool = True,\n",
        "        remove_stopwords: bool = True, remove_punctuation: bool = True) -> str:\n",
        "\n",
        "    if language not in stopwords.fileids():\n",
        "        raise ValueError(\"Unsupported language\")\n",
        "\n",
        "    accepted_stemmers = (\"snowball\", \"porter\", \"lancaster\")\n",
        "    if stemmer and stemmer not in accepted_stemmers:\n",
        "        raise ValueError(\"Stemmer must be one of\", accepted_stemmers)\n",
        "\n",
        "    # merge contractions\n",
        "    text: str = text.replace(\"'\", \"\").replace(\"â€™\", \"\")\n",
        "\n",
        "    # tokenize words, keep uppercase\n",
        "    tokenized: List = nltk.word_tokenize(text)\n",
        "\n",
        "    if remove_punctuation:\n",
        "        tokenized = [word for word in tokenized if word not in PUNCTUATION]\n",
        "\n",
        "    if remove_stopwords:\n",
        "        nltk_stopwords = stopwords.words(language)\n",
        "        words_to_exclude = set(\n",
        "            nltk_stopwords + ARTICLES_PREPOSITIONS.get(language, [])\n",
        "        ) - set(NEGATION_WORDS.get(language, []))\n",
        "\n",
        "        tokenized = [word for word in tokenized if word.lower() not in words_to_exclude]\n",
        "\n",
        "    words = tokenized\n",
        "\n",
        "    if stemmer:\n",
        "        if stemmer == \"porter\":\n",
        "            stemmer = PorterStemmer()\n",
        "        elif stemmer == \"snowball\":\n",
        "            stemmer = SnowballStemmer(language)\n",
        "        elif stemmer == \"lancaster\":\n",
        "            stemmer = LancasterStemmer()\n",
        "        words = [stemmer.stem(word) for word in tokenized]\n",
        "\n",
        "        # restore title_case and uppercase after stemming\n",
        "        case_restored = []\n",
        "        for i, word in enumerate(words):\n",
        "            if tokenized[i].istitle():\n",
        "                word = word.title()\n",
        "            elif tokenized[i].isupper():\n",
        "                word = word.upper()\n",
        "            case_restored.append(word)\n",
        "\n",
        "        words = case_restored\n",
        "    #delete the last period \n",
        "    words2 = words.pop()\n",
        "\n",
        "    # remove spaces\n",
        "    #join_str = \"\" if remove_spaces else \" \"\n",
        "    #trimmed: str = join_str.join(words).strip()\n",
        "    #if not remove_punctuation:\n",
        "        # this is a hack to remove spaces before punctuation\n",
        "        #trimmed = re.sub(r\"\\s([?.!,:;])\", r\"\\1\", trimmed)\n",
        "        \n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "rAswfSGKonqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text is from the input above\n",
        "trimmed_text = trim(text)\n",
        "print(trimmed_text)"
      ],
      "metadata": {
        "id": "nJjSEcZDo0PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "f8Uew0qs7tBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see if there is a valid number of tokens \n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "gwuQnaS17vKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numTokens = len(encoding.encode(trimmed_text))"
      ],
      "metadata": {
        "id": "L4B5qKtA7y9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just for comparison with original \n",
        "len(encoding.encode(text))"
      ],
      "metadata": {
        "id": "4wk_f72d8bRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if numTokens >= 4096:\n",
        "  print('TOO MANY TOKENS')\n",
        "else:\n",
        "  print('Go ahead')"
      ],
      "metadata": {
        "id": "rfVt-XiG9rAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Langchain and GPT-3.5 turbo"
      ],
      "metadata": {
        "id": "Crdhphr34Cdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "38ecVXK74Gl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "id": "wukJu-4D4MiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarization\n"
      ],
      "metadata": {
        "id": "-cBD2a7COStG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "chatGPT = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "hOWxZeP44V1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert at making strong factual summarizations.\\\n",
        "     Take the article submitted by the user and produce a factual useful summary\"),\n",
        "    HumanMessage(content=trimmed_text)\n",
        "]\n",
        "responses = chatGPT(messages)"
      ],
      "metadata": {
        "id": "EJXo5qg04z3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summarizing the text (something with langchain) \n",
        "summarizedText = responses\n",
        "print(summarizedText)\n",
        "\n"
      ],
      "metadata": {
        "id": "w6eGOH2jk4kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversion to realistic text to speech and read out \n",
        "\n",
        "(can take a while) "
      ],
      "metadata": {
        "id": "cW3KEC4PCA5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "w_GKdjSvR7I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#long form generation\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "\n",
        "from IPython.display import Audio\n",
        "import nltk  # we'll use this to split into sentences\n",
        "import numpy as np\n",
        "\n",
        "from bark.generation import (\n",
        "    generate_text_semantic,\n",
        "    preload_models,\n",
        ")\n",
        "from bark.api import semantic_to_waveform\n",
        "from bark import generate_audio, SAMPLE_RATE\n",
        "\n"
      ],
      "metadata": {
        "id": "Cl01EACYRdgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preload_models()"
      ],
      "metadata": {
        "id": "qGSEorjKkr4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script = summarizedText.replace(\"\\n\", \" \").strip()\n",
        "sentences = nltk.sent_tokenize(script)\n",
        "GEN_TEMP = 0.6\n",
        "SPEAKER = \"v2/en_speaker_6\"\n",
        "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
        "\n",
        "pieces = []\n",
        "for sentence in sentences:\n",
        "    semantic_tokens = generate_text_semantic(\n",
        "        sentence,\n",
        "        history_prompt=SPEAKER,\n",
        "        temp=GEN_TEMP,\n",
        "        min_eos_p=0.05,  # this controls how likely the generation is to end\n",
        "    )\n",
        "\n",
        "    audio_array = semantic_to_waveform(semantic_tokens, history_prompt=SPEAKER,)\n",
        "    pieces += [audio_array, silence.copy()]\n",
        "    Audio(np.concatenate(pieces), rate=SAMPLE_RATE)"
      ],
      "metadata": {
        "id": "ghvztaiTk917"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Licenses\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2023 Vlad Gheorghe\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in\n",
        "all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "THE SOFTWARE.\n",
        "\n",
        "___\n",
        "\n",
        "The MIT License\n",
        "\n",
        "Copyright (c) Harrison Chase\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in\n",
        "all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "THE SOFTWARE.\n",
        "\n",
        "___\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) Suno, Inc\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVOD7D633iKD"
      }
    }
  ]
}